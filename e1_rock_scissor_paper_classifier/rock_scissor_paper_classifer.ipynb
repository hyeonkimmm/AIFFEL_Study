{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비 -> 딥러닝 네트워크 설계 -> 학습 -> 테스트(평가)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 숫자 손글씨 Dataset 불러들이기\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전을 출력\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "print(len(x_train))  # x_train 배열의 크기를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고문헌 : MNIST DataSet :**<https://imyeonn.github.io>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 손글씨 이미지의 크기 : 28x28     \n",
    "Dataset 60,000장의 Training set 10,000장의 test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[1],cmap=plt.cm.binary)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index에 0에서 59999 사이 숫자를 지정해 보세요.\n",
    "index=10000     \n",
    "plt.imshow(x_train[index],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print( (index+1), '번째 이미지의 숫자는 바로 ',  y_train[index], '입니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 지정하여 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고** Matplotlib를 활용하여 시각화 할 수 있다.\n",
    "\n",
    "https://matplotlib.org/gallery.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습용 데이터와 시험용 데이터\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet이야기 https://tykimos.github.io/2017/03/25/Dataset_and_Fit_Talk/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공지능 모델을 훈련시키고 사용할 때, 일반적으로 입력은 0 에서 1 사이의 값으로 정규화 시켜주는 것이 좋습니다. MNIST 데이터는 각 픽셀의 값이 0 에서 255 사이 범위에 있으므로 데이터들을 255.0 으로 나누어주면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기\n",
    "### Sequenential Model을 사용\n",
    "---\n",
    "텐서플로우 케라스(tf.keras)에서 Sequential API라는 방법을 사용,  Sequential API는 개발의 자유도는 많이 떨어지지만, 매우 간단하게 딥러닝 모델을 만들어낼 수 있는 방법\n",
    "    아래 코드는 LeNet 이라는 딥러닝 네트워크를 설계한 내용\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model](keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크 입력 (데이터 갯수, 이미지크기x , 이미지 크기y, 채널수)    \n",
    "input_shape(28,28,1)로 지정했던 것 참고 -> 이에 채널 값 추가 해줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile과 fit을 통해 실제 교육을 해 줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 확인하기\n",
    "### 테스트 데이터로 성능을 확인\n",
    "위의 인식 정확도는 학습용 데이터(x_train)을 가지고 구한 것,    \n",
    "실제 테스트는 시험용 데이터(x_test)를 가지고 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어떤 데이터를 잘못 추론했는지 확인하기\n",
    "---\n",
    "model.evaluate 대신 model.predict()를 사용하면 확률 분포 체크 가능\n",
    "Mnist의 경우 10개의 클래스별 확률을 체크하고 그중 가장 높은 것이 model이 추론한 숫자가 되는 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = model.predict(x_test_reshaped)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 모델이 틀렸을 경우만 모아서 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "wrong_predict_list=[]\n",
    "for i, _ in enumerate(predicted_labels):\n",
    "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
    "    if predicted_labels[i] != y_test[i]:\n",
    "        wrong_predict_list.append(i)\n",
    "\n",
    "# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\n",
    "samples = random.choices(population=wrong_predict_list, k=5)\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
    "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
    "    plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 좋은 네트워크 만들기\n",
    "#### 하이퍼 파라미터 조정을 통한 모델 변경\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "313/313 - 2s - loss: 0.0421 - accuracy: 0.9904\n",
    "test_loss: 0.042079728096723557 \n",
    "test_accuracy: 0.9904000163078308\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 가위바위보 분류기 만들기\n",
    "웹캠으로 사진 빠르게 저장하기 https://teachablemachine.withgoogle.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 데이터 불러오기 + Resize \n",
    "숫자 손글씨의 경우 28x28이였으므로 가위 바위 보 이미지도 resize를 해준다.    \n",
    "이를 위해 PIL 라이브러리를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/envs/datascience/lib/python3.8/site-packages (7.2.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/paper\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"PNG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tree](tree.png)\n",
    "\n",
    "프로젝트 폴더 구조\n",
    "\n",
    "최종적으로 각각 데이터 700장씩 수집 완료\n",
    "\n",
    "각 사진마다 이미지 행렬을 복사 한 후 데이터 라벨링 작업 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 이미지 개수는 2100 입니다.\n",
      "x_train shape: (1680, 28, 28, 3)\n",
      "y_train shape: (1680,)\n",
      "x_test shape: (420, 28, 28, 3)\n",
      "y_test shape: (420,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2100   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx+=1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx+=1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"전체 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "x, y = load_data(image_dir_path)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image check code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[1500])\n",
    "print('라벨: ', y_train[1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계\n",
    "데이터의 준비 완료, 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               640400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1203      \n",
      "=================================================================\n",
      "Total params: 660,995\n",
      "Trainable params: 660,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=400 #기존 모델 16\n",
    "n_train_epoch=15\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 1.0010 - accuracy: 0.4821\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.6205 - accuracy: 0.7298\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.4398 - accuracy: 0.8226\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.3267 - accuracy: 0.8786\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.2599 - accuracy: 0.9101\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.9399\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 0s 9ms/step - loss: 0.1310 - accuracy: 0.9589\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0853 - accuracy: 0.9768\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0716 - accuracy: 0.9821\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0486 - accuracy: 0.9899\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.0391 - accuracy: 0.9911\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 1s 14ms/step - loss: 0.0285 - accuracy: 0.9940\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0212 - accuracy: 0.9964\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9970\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc98fb65610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 테스트를 하기 위해 전체 데이터의 20%인 420장으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - loss: 18.4774 - accuracy: 0.9690\n",
      "test_loss: 18.477401733398438 \n",
      "test_accuracy: 0.9690476059913635\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과에 대한 이유 및 고찰 내용\n",
    "---\n",
    "일단 처음 100장씩 교육했었을 때는 30%대의 인식율을 나타냈기 때문에 Data 개수의 문제가 있다고 판단했습니다.    \n",
    "Slack에서 외부의 자료를 받아 2000장 가깝게 재교육을 했으나 외부의 자료와 webcam을 통해 직접 마련한 DataSet의 배경도 그렇고 외부자료의    이미지 형태가 문제점이 많았기 때문에 인식률은 크게 개선되지 않았고, 따라서 외부자료는 다시 삭제하고 조원들의 데이터를 추가하여 최종적으로\n",
    "\n",
    "**전체 데이터 2100장**\n",
    "\n",
    "**Training Data 1680장**\n",
    "\n",
    "**Test Data 420장**\n",
    "\n",
    "으로 정해서 진행했습니다.\n",
    "\n",
    "Train data와 Test Data간의 차이가 심하면 인식률이 떨어져서 sklearn을 활용해서    \n",
    "train데이터와 test데이터를 split하여 구성하였습니다.\n",
    "데이터 셋을 더 추가하거나 아니면 딥러닝 모델을 고도화 하는 측면 혹은 이미지 데이터의 전처리를 통해 픽셀값을 좀 더 크게 한다면 인식률이 더 좋아질 것이라고 판단하고 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
